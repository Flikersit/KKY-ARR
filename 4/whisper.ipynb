{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea2e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import time\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0715305",
   "metadata": {},
   "outputs": [],
   "source": [
    "cz_reference = \"Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\"\n",
    "\n",
    "path_noise_snr0 = r\"D:\\prednasky\\ARR\\arr4\\jezero_snr0.ogg\"\n",
    "path_noise_snr10 = r\"D:\\prednasky\\ARR\\arr4\\jezero_snr10.ogg\"\n",
    "path_noise_snr20 = r\"D:\\prednasky\\ARR\\arr4\\jezero_snr20.ogg\"\n",
    "path_noise_snr30 = r\"D:\\prednasky\\ARR\\arr4\\jezero_snr30.ogg\"\n",
    "\n",
    "\n",
    "pavietrany_sar = r\"D:\\prednasky\\ARR\\arr4\\pavietrany_šar.ogg\"\n",
    "jezero = r\"D:\\prednasky\\ARR\\arr4\\jezero.ogg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538db7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(file, out_file, db):\n",
    "    audio, sr = sf.read(file)\n",
    "    snr_db = db\n",
    "    signal_power = np.mean(audio**2)\n",
    "\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = signal_power / snr_linear\n",
    "\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), audio.shape)\n",
    "\n",
    "    noisy_audio = audio + noise\n",
    "\n",
    "    sf.write(out_file, noisy_audio, sr)\n",
    "\n",
    "\n",
    "def calculate_wer(reference, hypothesis):\n",
    "\tref_words = reference.split()\n",
    "\thyp_words = hypothesis.split()\n",
    "\t# Counting the number of substitutions, deletions, and insertions\n",
    "\tsubstitutions = sum(1 for ref, hyp in zip(ref_words, hyp_words) if ref != hyp)\n",
    "\tdeletions = len(ref_words) - len(hyp_words)\n",
    "\tinsertions = len(hyp_words) - len(ref_words)\n",
    "\t# Total number of words in the reference text\n",
    "\ttotal_words = len(ref_words)\n",
    "\t# Calculating the Word Error Rate (WER)\n",
    "\twer = (substitutions + deletions + insertions) / total_words\n",
    "\treturn wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "355235ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise(jezero, path_noise_snr10, 10)\n",
    "add_noise(jezero, path_noise_snr20, 20)\n",
    "add_noise(jezero, path_noise_snr30, 30)\n",
    "add_noise(jezero, path_noise_snr0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c157520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0da7d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Výsledek rozpoznávání ===\n",
      "Rozpoznaný text :  Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "CZ reference    : Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "\n",
      "=== Statistiky ===\n",
      "Čas (s)         WER        SNR (dB)  \n",
      "16.951          0.000      -         \n",
      "\n",
      "=== Výsledek rozpoznávání ===\n",
      "Rozpoznaný text :  dass Nadiris v Istinn komaly vřeplhl doğ fully civil hladiny v šírov\n",
      "CZ reference    : Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "\n",
      "=== Statistiky ===\n",
      "Čas (s)         WER        SNR (dB)  \n",
      "63.134          1.000      0         \n",
      "\n",
      "=== Výsledek rozpoznávání ===\n",
      "Rozpoznaný text :  Modrý stín pomalu přeplouvá prostichou hladinu jezera.\n",
      "CZ reference    : Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "\n",
      "=== Statistiky ===\n",
      "Čas (s)         WER        SNR (dB)  \n",
      "16.469          0.375      10        \n",
      "\n",
      "=== Výsledek rozpoznávání ===\n",
      "Rozpoznaný text :  Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "CZ reference    : Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "\n",
      "=== Statistiky ===\n",
      "Čas (s)         WER        SNR (dB)  \n",
      "16.562          0.000      20        \n",
      "\n",
      "=== Výsledek rozpoznávání ===\n",
      "Rozpoznaný text :  Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "CZ reference    : Modrý stín pomalu přeplouvá přes tichou hladinu jezera.\n",
      "\n",
      "=== Statistiky ===\n",
      "Čas (s)         WER        SNR (dB)  \n",
      "16.194          0.000      30        \n"
     ]
    }
   ],
   "source": [
    "curr1 = time.time()\n",
    "result = model.transcribe(jezero)\n",
    "curr2 = time.time()\n",
    "\n",
    "wer = calculate_wer(cz_reference, result['text'])\n",
    "noise_level = \"-\"\n",
    "\n",
    "print(\"\\n=== Výsledek rozpoznávání ===\")\n",
    "print(f\"Rozpoznaný text : {result['text']}\")\n",
    "print(f\"CZ reference    : {cz_reference}\")\n",
    "\n",
    "print(\"\\n=== Statistiky ===\")\n",
    "print(f\"{'Čas (s)':<15} {'WER':<10} {'SNR (dB)':<10}\")\n",
    "print(f\"{curr2 - curr1:<15.3f} {wer:<10.3f} {noise_level:<10}\")\n",
    "\n",
    "\n",
    "curr1 = time.time()\n",
    "result = model.transcribe(path_noise_snr0)\n",
    "curr2 = time.time()\n",
    "\n",
    "wer = calculate_wer(cz_reference, result['text'])\n",
    "noise_level = \"0\"\n",
    "\n",
    "print(\"\\n=== Výsledek rozpoznávání ===\")\n",
    "print(f\"Rozpoznaný text : {result['text']}\")\n",
    "print(f\"CZ reference    : {cz_reference}\")\n",
    "\n",
    "print(\"\\n=== Statistiky ===\")\n",
    "print(f\"{'Čas (s)':<15} {'WER':<10} {'SNR (dB)':<10}\")\n",
    "print(f\"{curr2 - curr1:<15.3f} {wer:<10.3f} {noise_level:<10}\")\n",
    "\n",
    "\n",
    "\n",
    "curr1 = time.time()\n",
    "result = model.transcribe(path_noise_snr10)\n",
    "curr2 = time.time()\n",
    "\n",
    "wer = calculate_wer(cz_reference, result['text'])\n",
    "noise_level = \"10\"\n",
    "\n",
    "print(\"\\n=== Výsledek rozpoznávání ===\")\n",
    "print(f\"Rozpoznaný text : {result['text']}\")\n",
    "print(f\"CZ reference    : {cz_reference}\")\n",
    "\n",
    "print(\"\\n=== Statistiky ===\")\n",
    "print(f\"{'Čas (s)':<15} {'WER':<10} {'SNR (dB)':<10}\")\n",
    "print(f\"{curr2 - curr1:<15.3f} {wer:<10.3f} {noise_level:<10}\")\n",
    "\n",
    "\n",
    "curr1 = time.time()\n",
    "result = model.transcribe(path_noise_snr20)\n",
    "curr2 = time.time()\n",
    "\n",
    "wer = calculate_wer(cz_reference, result['text'])\n",
    "noise_level = \"20\"\n",
    "\n",
    "print(\"\\n=== Výsledek rozpoznávání ===\")\n",
    "print(f\"Rozpoznaný text : {result['text']}\")\n",
    "print(f\"CZ reference    : {cz_reference}\")\n",
    "\n",
    "print(\"\\n=== Statistiky ===\")\n",
    "print(f\"{'Čas (s)':<15} {'WER':<10} {'SNR (dB)':<10}\")\n",
    "print(f\"{curr2 - curr1:<15.3f} {wer:<10.3f} {noise_level:<10}\")\n",
    "\n",
    "\n",
    "\n",
    "curr1 = time.time()\n",
    "result = model.transcribe(path_noise_snr30)\n",
    "curr2 = time.time()\n",
    "\n",
    "wer = calculate_wer(cz_reference, result['text'])\n",
    "noise_level = \"30\"\n",
    "\n",
    "print(\"\\n=== Výsledek rozpoznávání ===\")\n",
    "print(f\"Rozpoznaný text : {result['text']}\")\n",
    "print(f\"CZ reference    : {cz_reference}\")\n",
    "\n",
    "print(\"\\n=== Statistiky ===\")\n",
    "print(f\"{'Čas (s)':<15} {'WER':<10} {'SNR (dB)':<10}\")\n",
    "print(f\"{curr2 - curr1:<15.3f} {wer:<10.3f} {noise_level:<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb15aceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Глядеть на брутный город и кремзать мемуары, Не варта вачей и не варта рук, Я гляджу на зоры, я гляджу на хмары, И слухаю власного сердца стук.', 'segments': [{'id': 0, 'seek': 0, 'start': 1.0, 'end': 4.12, 'text': ' Глядеть на брутный город и кремзать мемуары,', 'tokens': [50415, 7247, 2873, 856, 9108, 1470, 1268, 47220, 4441, 18750, 1006, 981, 7049, 1544, 2209, 1084, 8339, 48632, 11, 50571], 'temperature': 0.0, 'avg_logprob': -0.22980465760102142, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 1.418735848801589e-07}, {'id': 1, 'seek': 0, 'start': 4.58, 'end': 6.62, 'text': ' Не варта вачей и не варта рук,', 'tokens': [50594, 11512, 740, 2222, 10788, 740, 8314, 2345, 1006, 1725, 740, 2222, 10788, 36765, 11, 50696], 'temperature': 0.0, 'avg_logprob': -0.22980465760102142, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 1.418735848801589e-07}, {'id': 2, 'seek': 0, 'start': 6.86, 'end': 9.76, 'text': ' Я гляджу на зоры, я гляджу на хмары,', 'tokens': [50708, 4857, 2342, 2873, 856, 1820, 585, 1470, 1423, 42342, 11, 2552, 2342, 2873, 856, 1820, 585, 1470, 3490, 919, 48632, 11, 50853], 'temperature': 0.0, 'avg_logprob': -0.22980465760102142, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 1.418735848801589e-07}, {'id': 3, 'seek': 0, 'start': 10.18, 'end': 12.48, 'text': ' И слухаю власного сердца стук.', 'tokens': [50874, 3272, 4766, 11576, 3776, 740, 23511, 4699, 38479, 11530, 3266, 10282, 13, 50989], 'temperature': 0.0, 'avg_logprob': -0.22980465760102142, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 1.418735848801589e-07}], 'language': 'ru'}\n",
      "It takes: 20.750703811645508\n"
     ]
    }
   ],
   "source": [
    "curr1 = time.time()\n",
    "result = model.transcribe(pavietrany_sar)\n",
    "curr2 = time.time()\n",
    "print(result)\n",
    "\n",
    "print(\"It takes:\", curr2-curr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66db4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\_torchcodec.py:82\u001b[0m, in \u001b[0;36mload_with_torchcodec\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchcodec'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Wav2Vec2ForCTC\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marampacha/wav2vec2-large-xlsr-czech\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                                cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprednasky\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mARR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124marr4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 1. Загружаем OGG файл\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjezero\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m speech_array \u001b[38;5;241m=\u001b[39m speech_array\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОригинальная частота:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampling_rate)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\__init__.py:86\u001b[0m, in \u001b[0;36mload\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m     20\u001b[0m     frame_offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     backend: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source using TorchCodec's AudioDecoder.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m        by TorchCodec.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_with_torchcodec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\_torchcodec.py:84\u001b[0m, in \u001b[0;36mload_with_torchcodec\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchCodec is required for load_with_torchcodec. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install torchcodec to use this function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Parameter validation and warnings\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m normalize:\n",
      "\u001b[1;31mImportError\u001b[0m: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function."
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"arampacha/wav2vec2-large-xlsr-czech\",\n",
    "                                               cache_dir=r\"D:\\prednasky\\ARR\\arr4\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"arampacha/wav2vec2-large-xlsr-czech\",\n",
    "                                               cache_dir=r\"D:\\prednasky\\ARR\\arr4\")\n",
    "\n",
    "\n",
    "# 1. Загружаем OGG файл\n",
    "speech_array, sampling_rate = torchaudio.load(jezero)\n",
    "speech_array = speech_array.squeeze()\n",
    "\n",
    "print(\"Оригинальная частота:\", sampling_rate)\n",
    "\n",
    "# 2. Если частота ≠ 16000 → ресемплим\n",
    "if sampling_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, 16000)\n",
    "    speech_array = resampler(speech_array)\n",
    "    sampling_rate = 16000\n",
    "\n",
    "# 3. Конвертируем в numpy\n",
    "speech = speech_array.numpy()\n",
    "\n",
    "# 4. Передаём в модель\n",
    "inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "text = processor.decode(pred_ids[0])\n",
    "\n",
    "print(\"Распознанный текст:\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
